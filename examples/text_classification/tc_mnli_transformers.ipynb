{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sarcasm Classification Using BERT Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Need PyTorch 1.5+. 1.4 will report segment error when streaming to GPU memory.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from utils_nlp.common.timer import Timer\n",
    "from utils_nlp.common.pytorch_utils import dataloader_from_dataset\n",
    "from utils_nlp.dataset.multinli import load_pandas_df\n",
    "from utils_nlp.models.transformers.sequence_classification import (\n",
    "    Processor, SequenceClassifier)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1607581587633
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "In this notebook, we use BERT to classify sarcasm in Twitter responses.\n",
    "We use pre-trained BERT model followed by fine-tuning with labeled data in the training set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# notebook parameters\n",
    "DATA_FOLDER = TemporaryDirectory().name\n",
    "CACHE_DIR = TemporaryDirectory().name\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "# Student tier, only 1 GPU available\n",
    "NUM_GPUS = 1\n",
    "MAX_LEN = 100\n",
    "TRAIN_DATA_FRACTION = 1\n",
    "TEST_DATA_FRACTION = 1\n",
    "TRAIN_SIZE = 0.95\n",
    "LABEL_COL = \"label\"\n",
    "TEXT_COL = \"response\"\n",
    "TRAIN_DATA_PATH = \"train.jsonl\""
   ],
   "outputs": [],
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1607581702666
    },
    "tags": [
     "parameters"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Dataset\n",
    "We read the training data and keep only label and responses. Then remove the '@USER' tag since it doesn't contribute to sarcasm.\n",
    "Context can be used in improving accuracy with [SEP] seperator in BERT but not explored in this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "data = []\n",
    "with open(TRAIN_DATA_PATH) as f:\n",
    "    for data_row in f:\n",
    "        row = []\n",
    "        parsed_json = json.loads(data_row)\n",
    "        row.append(parsed_json['label'])\n",
    "        row.append(parsed_json['response'])\n",
    "        data.append(row)\n",
    "\n",
    "for row in data:\n",
    "    row[1] = row[1].replace('@USER ', '')\n",
    "\n",
    "# Build dataframe\n",
    "df = pd.DataFrame(data=data, columns=[\"label\", \"response\"])"
   ],
   "outputs": [],
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1607581704811
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspect the training dta\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 16,
     "data": {
      "text/plain": "            label                                           response\n0         SARCASM  I don't get this .. obviously you do care or y...\n1         SARCASM  trying to protest about . Talking about him an...\n2         SARCASM  He makes an insane about of money from the MOV...\n3         SARCASM  Meanwhile Trump won't even release his SAT sco...\n4         SARCASM  Pretty Sure the Anti-Lincoln Crowd Claimed Tha...\n...           ...                                                ...\n4995  NOT_SARCASM  You don't . I have purchased a lot on Amazon (...\n4996  NOT_SARCASM  #Emotions you say ðŸ¤” never knew that I think I ...\n4997  NOT_SARCASM  You are so right ... \" Yes ! #Silence is not #...\n4998  NOT_SARCASM  Another lazy delusional voter who takes the wo...\n4999  NOT_SARCASM  I hope you know no news outlet from Nigeria ha...\n\n[5000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SARCASM</td>\n      <td>I don't get this .. obviously you do care or y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SARCASM</td>\n      <td>trying to protest about . Talking about him an...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SARCASM</td>\n      <td>He makes an insane about of money from the MOV...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SARCASM</td>\n      <td>Meanwhile Trump won't even release his SAT sco...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SARCASM</td>\n      <td>Pretty Sure the Anti-Lincoln Crowd Claimed Tha...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>NOT_SARCASM</td>\n      <td>You don't . I have purchased a lot on Amazon (...</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>NOT_SARCASM</td>\n      <td>#Emotions you say ðŸ¤” never knew that I think I ...</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>NOT_SARCASM</td>\n      <td>You are so right ... \" Yes ! #Silence is not #...</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>NOT_SARCASM</td>\n      <td>Another lazy delusional voter who takes the wo...</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>NOT_SARCASM</td>\n      <td>I hope you know no news outlet from Nigeria ha...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1607581706656
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df[[LABEL_COL, TEXT_COL]].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 17,
     "data": {
      "text/plain": "     label                                           response\n0  SARCASM  I don't get this .. obviously you do care or y...\n1  SARCASM  trying to protest about . Talking about him an...\n2  SARCASM  He makes an insane about of money from the MOV...\n3  SARCASM  Meanwhile Trump won't even release his SAT sco...\n4  SARCASM  Pretty Sure the Anti-Lincoln Crowd Claimed Tha...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SARCASM</td>\n      <td>I don't get this .. obviously you do care or y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SARCASM</td>\n      <td>trying to protest about . Talking about him an...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SARCASM</td>\n      <td>He makes an insane about of money from the MOV...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SARCASM</td>\n      <td>Meanwhile Trump won't even release his SAT sco...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SARCASM</td>\n      <td>Pretty Sure the Anti-Lincoln Crowd Claimed Tha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1607581708488
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We evaluated the model by splitting the data for training and testing. In this case, since the model was proved to be good,\n",
    "we use all data for training.\n",
    "Next we encode the class labels. SARCASM = 1, NOT_SARCASM = 0."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# split\n",
    "df_train, df_test = train_test_split(df, train_size = TRAIN_SIZE, random_state=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1607581710513
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# sample\n",
    "df_train = df_train.sample(frac=0.95).reset_index(drop=True)\n"
   ],
   "outputs": [],
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1607581754219
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# A simple statistics of the training data regarding label and count.\n",
    "df_train[LABEL_COL].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 23,
     "data": {
      "text/plain": "1    2270\n0    2242\nName: label, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1607581758302
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[LABEL_COL] = label_encoder.fit_transform(df_train[LABEL_COL])\n",
    "num_labels = len(np.unique(df_train[LABEL_COL]))"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1607581767637
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Number of unique labels: {}\".format(num_labels))\n",
    "print(\"Number of training examples: {}\".format(df_train.shape[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of unique labels: 2\n",
      "Number of training examples: 4512\n"
     ]
    }
   ],
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1607581857675
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load test data. Same processing method.\n",
    "data = []\n",
    "with open(\"test.jsonl\") as f:\n",
    "    for data_row in f:\n",
    "        row = []\n",
    "        parsed_json = json.loads(data_row)\n",
    "        row.append(parsed_json['id'])\n",
    "        row.append(parsed_json['response'])\n",
    "        data.append(row)\n",
    "\n",
    "for row in data:\n",
    "    row[1] = row[1].replace('@USER ', '')\n",
    "# print(data[0])\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"id\", \"response\"])\n",
    "df_prod = df.reset_index(drop=True)\n",
    "df_prod\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 27,
     "data": {
      "text/plain": "                id                                           response\n0        twitter_1  My 3 year old , that just finished reading Nie...\n1        twitter_2  How many verifiable lies has he told now ? 15,...\n2        twitter_3  Maybe Docs just a scrub of a coach ... I mean ...\n3        twitter_4  is just a cover up for the real hate inside . ...\n4        twitter_5      The irony being that he even has to ask why .\n...            ...                                                ...\n1795  twitter_1796  is definitely the best out there . No question...\n1796  twitter_1797  Ye let her out run wild and infect 10000 more ...\n1797  twitter_1798       Thanks for that , I would have never known .\n1798  twitter_1799  Yes also #found this on #new with loads of <UR...\n1799  twitter_1800  you still need to send the link to the fan you...\n\n[1800 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>twitter_1</td>\n      <td>My 3 year old , that just finished reading Nie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>twitter_2</td>\n      <td>How many verifiable lies has he told now ? 15,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>twitter_3</td>\n      <td>Maybe Docs just a scrub of a coach ... I mean ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitter_4</td>\n      <td>is just a cover up for the real hate inside . ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>twitter_5</td>\n      <td>The irony being that he even has to ask why .</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1795</th>\n      <td>twitter_1796</td>\n      <td>is definitely the best out there . No question...</td>\n    </tr>\n    <tr>\n      <th>1796</th>\n      <td>twitter_1797</td>\n      <td>Ye let her out run wild and infect 10000 more ...</td>\n    </tr>\n    <tr>\n      <th>1797</th>\n      <td>twitter_1798</td>\n      <td>Thanks for that , I would have never known .</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>twitter_1799</td>\n      <td>Yes also #found this on #new with loads of &lt;UR...</td>\n    </tr>\n    <tr>\n      <th>1799</th>\n      <td>twitter_1800</td>\n      <td>you still need to send the link to the fan you...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1800 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1607581822991
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select Pretrained Models\n",
    "\n",
    "We use pre-trained model provided by [Hugging Face](https://github.com/huggingface/transformers).\n",
    "After evaluating \"distilbert-base-uncased\", \"roberta-base\", \"xlnet-base-cased\", we decided to go with a more complex model:\n",
    "\"bert-large-cased-whole-word-masking\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Now we fine-tune the model to perform sarcasm detection.\n",
    "model_name = 'bert-large-cased-whole-word-masking'\n",
    "processor = Processor(\n",
    "        model_name=model_name,\n",
    "        to_lower=model_name.endswith(\"uncased\"),\n",
    "        cache_dir=CACHE_DIR,\n",
    "    )\n",
    "train_dataset = processor.dataset_from_dataframe(\n",
    "        df_train, TEXT_COL, LABEL_COL, max_len=MAX_LEN\n",
    "    )\n",
    "train_dataloader = dataloader_from_dataset(\n",
    "        train_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=True\n",
    "    )\n",
    "\n",
    "# fine-tune\n",
    "classifier = SequenceClassifier(\n",
    "        model_name=model_name, num_labels=num_labels, cache_dir=CACHE_DIR\n",
    "    )\n",
    "with Timer() as t:\n",
    "        classifier.fit(\n",
    "            train_dataloader, num_epochs=NUM_EPOCHS, num_gpus=NUM_GPUS, verbose=False,\n",
    "        )\n",
    "train_time = t.interval / 3600\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=625.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fc0114c77594b55acae4a581f7b931c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9abb304515514aa3a9a46e9f4b0ccf32"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1338743948.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69a4123087284aa59eb16bc022e08baf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1607582023454
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Produce classification result.\n",
    "prod_dataset = processor.dataset_from_dataframe(\n",
    "        df_prod, TEXT_COL, max_len=MAX_LEN\n",
    "    )\n",
    "prod_dataloader = dataloader_from_dataset(\n",
    "        prod_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=False\n",
    "    )\n",
    "# predict\n",
    "preds = classifier.predict(prod_dataloader, num_gpus=NUM_GPUS, verbose=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Materialize results to file.\n",
    "with open('answer.txt', 'w') as out:\n",
    "    for index,label in enumerate(preds):\n",
    "        res = \"\"\n",
    "        if label == 1:\n",
    "            res = 'SARCASM'\n",
    "        if label == 0:\n",
    "            res = 'NOT_CARCASM'\n",
    "        line = \"twitter_%s,%s\\n\"%(str(index + 1),res)\n",
    "        out.write(line)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "outputs": [],
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1607585984716
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "preds\n",
    "with open('answer.txt', 'w') as out:\n",
    "    for index,label in enumerate(preds):\n",
    "        res = \"\"\n",
    "        if label == 1:\n",
    "            res = 'SARCASM'\n",
    "        if label == 0:\n",
    "            res = 'NOT_CARCASM'\n",
    "        line = \"twitter_%s,%s\\n\"%(str(index + 1),res)\n",
    "        out.write(line)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1607586288455
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate\n",
    "\n",
    "Finally, we report the accuracy and F1-score metrics for each model, as well as the fine-tuning time in hours."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 61,
     "data": {
      "text/plain": "           distilbert-base-uncased  roberta-base  xlnet-base-cased\naccuracy                  0.784800      0.753600          0.770400\nf1-score                  0.784064      0.751230          0.769815\ntime(hrs)                 0.029202      0.038811          0.053048",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distilbert-base-uncased</th>\n      <th>roberta-base</th>\n      <th>xlnet-base-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>0.784800</td>\n      <td>0.753600</td>\n      <td>0.770400</td>\n    </tr>\n    <tr>\n      <th>f1-score</th>\n      <td>0.784064</td>\n      <td>0.751230</td>\n      <td>0.769815</td>\n    </tr>\n    <tr>\n      <th>time(hrs)</th>\n      <td>0.029202</td>\n      <td>0.038811</td>\n      <td>0.053048</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 61,
   "metadata": {
    "gather": {
     "logged": 1607578991728
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# for testing\n",
    "sb.glue(\"accuracy\", df_results.iloc[0, :].mean())\n",
    "sb.glue(\"f1\", df_results.iloc[1, :].mean())"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "outputs": [],
   "execution_count": null,
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "nlp_gpu"
  },
  "kernelspec": {
   "name": "nlp_gpu",
   "language": "python",
   "display_name": "Python (nlp_gpu)"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}