{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Copyright (c) Microsoft Corporation. All rights reserved.*\n",
        "\n",
        "*Licensed under the MIT License.*\n",
        "\n",
        "# Text Classification of MultiNLI Sentences using Multiple Transformer Models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scrapbook as sb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "from utils_nlp.common.timer import Timer\n",
        "from utils_nlp.common.pytorch_utils import dataloader_from_dataset\n",
        "from utils_nlp.dataset.multinli import load_pandas_df\n",
        "from utils_nlp.models.transformers.sequence_classification import (\n",
        "    Processor, SequenceClassifier)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1607581587633
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "In this notebook, we fine-tune and evaluate a number of pretrained models on a subset of the [MultiNLI](https://www.nyu.edu/projects/bowman/multinli/) dataset.\n",
        "\n",
        "We use a [sequence classifier](../../utils_nlp/models/transformers/sequence_classification.py) that wraps [Hugging Face's PyTorch implementation](https://github.com/huggingface/transformers) of different transformers, like [BERT](https://github.com/google-research/bert), [XLNet](https://github.com/zihangdai/xlnet), and [RoBERTa](https://github.com/pytorch/fairseq)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# notebook parameters\n",
        "DATA_FOLDER = TemporaryDirectory().name\n",
        "CACHE_DIR = TemporaryDirectory().name\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "NUM_GPUS = 1\n",
        "MAX_LEN = 100\n",
        "TRAIN_DATA_FRACTION = 1\n",
        "TEST_DATA_FRACTION = 1\n",
        "TRAIN_SIZE = 0.95\n",
        "LABEL_COL = \"label\"\n",
        "TEXT_COL = \"response\"\n",
        "MODEL_NAMES = [\"distilbert-base-uncased\", \"roberta-base\", \"xlnet-base-cased\"]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1607581702666
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Dataset\n",
        "We start by loading a subset of the data. The following function also downloads and extracts the files, if they don't exist in the data folder.\n",
        "\n",
        "The MultiNLI dataset is mainly used for natural language inference (NLI) tasks, where the inputs are sentence pairs and the labels are entailment indicators. The sentence pairs are also classified into *genres* that allow for more coverage and better evaluation of NLI models.\n",
        "\n",
        "For our classification task, we use the first sentence only as the text input, and the corresponding genre as the label. We select the examples corresponding to one of the entailment labels (*neutral* in this case) to avoid duplicate rows, as the sentences are not unique, whereas the sentence pairs are."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# df = load_pandas_df(DATA_FOLDER, \"train\")\n",
        "# df = df[df[\"gold_label\"]==\"neutral\"]  # get unique sentences\n",
        "\n",
        "data = []\n",
        "with open(\"train.jsonl\") as f:\n",
        "    for data_row in f:\n",
        "        row = []\n",
        "        parsed_json = json.loads(data_row)\n",
        "        row.append(parsed_json['label'])\n",
        "        row.append(parsed_json['response'])\n",
        "        data.append(row)\n",
        "\n",
        "for row in data:\n",
        "    row[1] = row[1].replace('@USER ', '')\n",
        "# print(data[0])\n",
        "\n",
        "df = pd.DataFrame(data=data, columns=[\"label\", \"response\"])"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1607581704811
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect if train dataframe loaded\n",
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "            label                                           response\n0         SARCASM  I don't get this .. obviously you do care or y...\n1         SARCASM  trying to protest about . Talking about him an...\n2         SARCASM  He makes an insane about of money from the MOV...\n3         SARCASM  Meanwhile Trump won't even release his SAT sco...\n4         SARCASM  Pretty Sure the Anti-Lincoln Crowd Claimed Tha...\n...           ...                                                ...\n4995  NOT_SARCASM  You don't . I have purchased a lot on Amazon (...\n4996  NOT_SARCASM  #Emotions you say ðŸ¤” never knew that I think I ...\n4997  NOT_SARCASM  You are so right ... \" Yes ! #Silence is not #...\n4998  NOT_SARCASM  Another lazy delusional voter who takes the wo...\n4999  NOT_SARCASM  I hope you know no news outlet from Nigeria ha...\n\n[5000 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SARCASM</td>\n      <td>I don't get this .. obviously you do care or y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SARCASM</td>\n      <td>trying to protest about . Talking about him an...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SARCASM</td>\n      <td>He makes an insane about of money from the MOV...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SARCASM</td>\n      <td>Meanwhile Trump won't even release his SAT sco...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SARCASM</td>\n      <td>Pretty Sure the Anti-Lincoln Crowd Claimed Tha...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>NOT_SARCASM</td>\n      <td>You don't . I have purchased a lot on Amazon (...</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>NOT_SARCASM</td>\n      <td>#Emotions you say ðŸ¤” never knew that I think I ...</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>NOT_SARCASM</td>\n      <td>You are so right ... \" Yes ! #Silence is not #...</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>NOT_SARCASM</td>\n      <td>Another lazy delusional voter who takes the wo...</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>NOT_SARCASM</td>\n      <td>I hope you know no news outlet from Nigeria ha...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607581706656
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[[LABEL_COL, TEXT_COL]].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "     label                                           response\n0  SARCASM  I don't get this .. obviously you do care or y...\n1  SARCASM  trying to protest about . Talking about him an...\n2  SARCASM  He makes an insane about of money from the MOV...\n3  SARCASM  Meanwhile Trump won't even release his SAT sco...\n4  SARCASM  Pretty Sure the Anti-Lincoln Crowd Claimed Tha...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SARCASM</td>\n      <td>I don't get this .. obviously you do care or y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SARCASM</td>\n      <td>trying to protest about . Talking about him an...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SARCASM</td>\n      <td>He makes an insane about of money from the MOV...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SARCASM</td>\n      <td>Meanwhile Trump won't even release his SAT sco...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SARCASM</td>\n      <td>Pretty Sure the Anti-Lincoln Crowd Claimed Tha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1607581708488
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data for training and testing, sample a fraction for faster execution, and encode the class labels:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# split\n",
        "df_train, df_test = train_test_split(df, train_size = TRAIN_SIZE, random_state=0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1607581710513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "df_train = df_train.sample(frac=0.95).reset_index(drop=True)\n",
        "# df_test = df_test.sample(frac=TEST_DATA_FRACTION).reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1607581754219
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The examples in the dataset are grouped into 5 genres:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[LABEL_COL].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "1    2270\n0    2242\nName: label, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1607581758302
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df_train[LABEL_COL] = label_encoder.fit_transform(df_train[LABEL_COL])\n",
        "# df_test[LABEL_COL] = label_encoder.transform(df_test[LABEL_COL])\n",
        "df_train\n",
        "num_labels = len(np.unique(df_train[LABEL_COL]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1607581767637
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of unique labels: {}\".format(num_labels))\n",
        "print(\"Number of training examples: {}\".format(df_train.shape[0]))\n",
        "# print(\"Number of testing examples: {}\".format(df_test.shape[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 2\n",
            "Number of training examples: 4512\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1607581857675
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Pretrained Models\n",
        "\n",
        "Several pretrained models have been made available by [Hugging Face](https://github.com/huggingface/transformers). For text classification, the following pretrained models are supported."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"model_name\": SequenceClassifier.list_supported_models()})"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 57,
          "data": {
            "text/plain": "                                     model_name\n0                                albert-base-v1\n1                                albert-base-v2\n2                               albert-large-v1\n3                               albert-large-v2\n4                              albert-xlarge-v1\n..                                          ...\n68  xlm-roberta-large-finetuned-conll02-spanish\n69  xlm-roberta-large-finetuned-conll03-english\n70   xlm-roberta-large-finetuned-conll03-german\n71                             xlnet-base-cased\n72                            xlnet-large-cased\n\n[73 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>albert-base-v1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>albert-base-v2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>albert-large-v1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>albert-large-v2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>albert-xlarge-v1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>xlm-roberta-large-finetuned-conll02-spanish</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>xlm-roberta-large-finetuned-conll03-english</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>xlm-roberta-large-finetuned-conll03-german</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>xlnet-base-cased</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>xlnet-large-cased</td>\n    </tr>\n  </tbody>\n</table>\n<p>73 rows Ã— 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1607578173548
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune\n",
        "\n",
        "Our wrappers make it easy to fine-tune different models in a unified way, hiding the preprocessing details that are needed before training. In this example, we're going to select the following models and use the same piece of code to fine-tune them on our genre classification task. Note that some models were pretrained on multilingual datasets and can be used with non-English datasets."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(MODEL_NAMES)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['distilbert-base-uncased', 'roberta-base', 'xlnet-base-cased']\n"
          ]
        }
      ],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1607578182209
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each pretrained model, we preprocess the data, fine-tune the classifier, score the test set, and store the evaluation results."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# results = {}\n",
        "# result_doc = {}\n",
        "# for model_name in tqdm(MODEL_NAMES, disable=True):\n",
        "\n",
        "#     # preprocess\n",
        "#     processor = Processor(\n",
        "#         model_name=model_name,\n",
        "#         to_lower=model_name.endswith(\"uncased\"),\n",
        "#         cache_dir=CACHE_DIR,\n",
        "#     )\n",
        "#     train_dataset = processor.dataset_from_dataframe(\n",
        "#         df_train, TEXT_COL, LABEL_COL, max_len=MAX_LEN\n",
        "#     )\n",
        "#     train_dataloader = dataloader_from_dataset(\n",
        "#         train_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=True\n",
        "#     )\n",
        "#     test_dataset = processor.dataset_from_dataframe(\n",
        "#         df_test, TEXT_COL, LABEL_COL, max_len=MAX_LEN\n",
        "#     )\n",
        "#     test_dataloader = dataloader_from_dataset(\n",
        "#         test_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=False\n",
        "#     )\n",
        "\n",
        "#     # fine-tune\n",
        "#     classifier = SequenceClassifier(\n",
        "#         model_name=model_name, num_labels=num_labels, cache_dir=CACHE_DIR\n",
        "#     )\n",
        "#     with Timer() as t:\n",
        "#         classifier.fit(\n",
        "#             train_dataloader, num_epochs=NUM_EPOCHS, num_gpus=NUM_GPUS, verbose=False,\n",
        "#         )\n",
        "#     train_time = t.interval / 3600\n",
        "\n",
        "#     # predict\n",
        "#     preds = classifier.predict(test_dataloader, num_gpus=NUM_GPUS, verbose=False)\n",
        "\n",
        "#     # eval\n",
        "#     accuracy = accuracy_score(df_test[LABEL_COL], preds)\n",
        "#     class_report = classification_report(\n",
        "#         df_test[LABEL_COL], preds, target_names=label_encoder.classes_, output_dict=True\n",
        "#     )\n",
        "\n",
        "#     # save results\n",
        "#     results[model_name] = {\n",
        "#         \"accuracy\": accuracy,\n",
        "#         \"f1-score\": class_report[\"macro avg\"][\"f1-score\"],\n",
        "#         \"time(hrs)\": train_time,\n",
        "#     }"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=442.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82d05970454148e88d41d217e3a6f8e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c14a6b5eac8341d1bc8fcc7784fc1999"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=267967963.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65b3f1a2ddab4d0d888cc994f294aa1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/conda/conda-bld/pytorch_1591914838379/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=481.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d6f3701994a4b6ea7bfb9af76cc8a06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=898823.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ab5670294d241dc92d89b2f9a066367"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ac55449339943b59ab6cd8cd63b509d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=501200538.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8171748c9d1248c4a275ab54f520f9c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=760.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc455a1ec4384dabb88453a36c01b0e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=798011.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f2a6264c08944f985c324002bbd9a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=467042463.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4778fa7101e2447796d32f6dae5e6422"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1607578708518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open(\"test.jsonl\") as f:\n",
        "    for data_row in f:\n",
        "        row = []\n",
        "        parsed_json = json.loads(data_row)\n",
        "        row.append(parsed_json['id'])\n",
        "        row.append(parsed_json['response'])\n",
        "        data.append(row)\n",
        "\n",
        "for row in data:\n",
        "    row[1] = row[1].replace('@USER ', '')\n",
        "# print(data[0])\n",
        "\n",
        "df = pd.DataFrame(data=data, columns=[\"id\", \"response\"])\n",
        "df_prod = df.reset_index(drop=True)\n",
        "df_prod\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "                id                                           response\n0        twitter_1  My 3 year old , that just finished reading Nie...\n1        twitter_2  How many verifiable lies has he told now ? 15,...\n2        twitter_3  Maybe Docs just a scrub of a coach ... I mean ...\n3        twitter_4  is just a cover up for the real hate inside . ...\n4        twitter_5      The irony being that he even has to ask why .\n...            ...                                                ...\n1795  twitter_1796  is definitely the best out there . No question...\n1796  twitter_1797  Ye let her out run wild and infect 10000 more ...\n1797  twitter_1798       Thanks for that , I would have never known .\n1798  twitter_1799  Yes also #found this on #new with loads of <UR...\n1799  twitter_1800  you still need to send the link to the fan you...\n\n[1800 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>twitter_1</td>\n      <td>My 3 year old , that just finished reading Nie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>twitter_2</td>\n      <td>How many verifiable lies has he told now ? 15,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>twitter_3</td>\n      <td>Maybe Docs just a scrub of a coach ... I mean ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>twitter_4</td>\n      <td>is just a cover up for the real hate inside . ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>twitter_5</td>\n      <td>The irony being that he even has to ask why .</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1795</th>\n      <td>twitter_1796</td>\n      <td>is definitely the best out there . No question...</td>\n    </tr>\n    <tr>\n      <th>1796</th>\n      <td>twitter_1797</td>\n      <td>Ye let her out run wild and infect 10000 more ...</td>\n    </tr>\n    <tr>\n      <th>1797</th>\n      <td>twitter_1798</td>\n      <td>Thanks for that , I would have never known .</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>twitter_1799</td>\n      <td>Yes also #found this on #new with loads of &lt;UR...</td>\n    </tr>\n    <tr>\n      <th>1799</th>\n      <td>twitter_1800</td>\n      <td>you still need to send the link to the fan you...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1800 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607581822991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-large-cased-whole-word-masking'\n",
        "processor = Processor(\n",
        "        model_name=model_name,\n",
        "        to_lower=model_name.endswith(\"uncased\"),\n",
        "        cache_dir=CACHE_DIR,\n",
        "    )\n",
        "train_dataset = processor.dataset_from_dataframe(\n",
        "        df_train, TEXT_COL, LABEL_COL, max_len=MAX_LEN\n",
        "    )\n",
        "train_dataloader = dataloader_from_dataset(\n",
        "        train_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=True\n",
        "    )\n",
        "\n",
        "# fine-tune\n",
        "classifier = SequenceClassifier(\n",
        "        model_name=model_name, num_labels=num_labels, cache_dir=CACHE_DIR\n",
        "    )\n",
        "with Timer() as t:\n",
        "        classifier.fit(\n",
        "            train_dataloader, num_epochs=NUM_EPOCHS, num_gpus=NUM_GPUS, verbose=False,\n",
        "        )\n",
        "train_time = t.interval / 3600\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=625.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fc0114c77594b55acae4a581f7b931c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9abb304515514aa3a9a46e9f4b0ccf32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1338743948.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69a4123087284aa59eb16bc022e08baf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607582023454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prod_dataset = processor.dataset_from_dataframe(\n",
        "        df_prod, TEXT_COL, max_len=MAX_LEN\n",
        "    )\n",
        "prod_dataloader = dataloader_from_dataset(\n",
        "        prod_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS, shuffle=False\n",
        "    )\n",
        "    # predict\n",
        "preds = classifier.predict(prod_dataloader, num_gpus=NUM_GPUS, verbose=False)"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607585984716
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds\n",
        "with open('answer.txt', 'w') as out:\n",
        "    for index,label in enumerate(preds):\n",
        "        res = \"\"\n",
        "        if label == 1:\n",
        "            res = 'SARCASM'\n",
        "        if label == 0:\n",
        "            res = 'NOT_CARCASM'\n",
        "        line = \"twitter_%s,%s\\n\"%(str(index + 1),res)\n",
        "        out.write(line)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607586288455
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate\n",
        "\n",
        "Finally, we report the accuracy and F1-score metrics for each model, as well as the fine-tuning time in hours."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "df_results"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "           distilbert-base-uncased  roberta-base  xlnet-base-cased\naccuracy                  0.784800      0.753600          0.770400\nf1-score                  0.784064      0.751230          0.769815\ntime(hrs)                 0.029202      0.038811          0.053048",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distilbert-base-uncased</th>\n      <th>roberta-base</th>\n      <th>xlnet-base-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>0.784800</td>\n      <td>0.753600</td>\n      <td>0.770400</td>\n    </tr>\n    <tr>\n      <th>f1-score</th>\n      <td>0.784064</td>\n      <td>0.751230</td>\n      <td>0.769815</td>\n    </tr>\n    <tr>\n      <th>time(hrs)</th>\n      <td>0.029202</td>\n      <td>0.038811</td>\n      <td>0.053048</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1607578991728
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing\n",
        "sb.glue(\"accuracy\", df_results.iloc[0, :].mean())\n",
        "sb.glue(\"f1\", df_results.iloc[1, :].mean())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "nlp_gpu"
    },
    "kernelspec": {
      "name": "nlp_gpu",
      "language": "python",
      "display_name": "Python (nlp_gpu)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}